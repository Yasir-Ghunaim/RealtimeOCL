{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook cleans up the metadata for the CLOC dataset. Note: you must first donwload the CLOC dataset before using this notebook. \n",
    "\n",
    "CLOC dataset provides a huge list of image URLs hosted in Flickr server. However, some of these URLs may no longer be valid. This notebook removes these invalid URLs in the metadata of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/path/to/CLOC/release/dataset/images/\"\n",
    "metadata_path = \"/path/to/CLOC/metadata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert root != \"/path/to/CLOC/release/dataset/images/\", \"Please provide a valid path\"\n",
    "assert metadata_path != \"/path/to/CLOC/metadata/\", \"Please provide a valid path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.load(metadata_path + 'train_labels.torchSave')\n",
    "time_taken = torch.load(metadata_path + 'train_time.torchSave')\n",
    "user = torch.load(metadata_path + 'train_user.torchSave')\n",
    "userID = torch.load(metadata_path + 'train_userID.torchSave')\n",
    "store_loc = torch.load(metadata_path + 'train_store_loc.torchSave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether each image pointer exists in the downloaded files, if so add it to the index_list\n",
    "index_list = []\n",
    "for i in tqdm(range(len(labels))):\n",
    "    path = root + store_loc[i].strip()\n",
    "    if os.path.isfile(path):\n",
    "        index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_clean = [labels[i] for i in index_list]\n",
    "time_taken_clean = [time_taken[i] for i in index_list]\n",
    "user_clean = [user[i] for i in index_list]\n",
    "userID_clean = [userID[i] for i in index_list]\n",
    "store_loc_clean = [store_loc[i] for i in index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(labels_clean) > 0, \"Something went wrong, ensure that the root path is valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may perform some sanity checks before overwriting the original CLOC metadata with the following files.\n",
    "torch.save(labels_clean, metadata_path + 'train_labels.torchSave')\n",
    "torch.save(time_taken_clean, metadata_path + 'train_time.torchSave')\n",
    "torch.save(user_clean, metadata_path + 'train_user.torchSave')\n",
    "torch.save(userID_clean, metadata_path + 'train_userID.torchSave')\n",
    "torch.save(store_loc_clean, metadata_path + 'train_store_loc.torchSave')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_file = \"yfcc100m_metadata_with_labels_usedDataRatio0.05_t110000_t250_valid_files_2004To2014_compact_val.csv\"\n",
    "df = pd.read_csv(metadata_path + test_set_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether each image pointer exists in the downloaded files, if so add it to the index_list\n",
    "index_list = []\n",
    "for i in tqdm(range(len(df.iloc[:,4]))):\n",
    "    path = root + df.iloc[i,4].strip()\n",
    "    if os.path.isfile(path):\n",
    "        index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.iloc[index_list,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(index_list) > 0, \"Something went wrong, ensure that the root path is valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(metadata_path + test_set_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
